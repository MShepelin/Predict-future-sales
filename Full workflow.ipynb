{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Setting\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "sales_train        = pd.read_csv('./readonly/sales_train.csv')\n",
    "test               = pd.read_csv('./readonly/test.csv')\n",
    "items              = pd.read_csv('./readonly/items.csv')\n",
    "item_categories    = pd.read_csv('./readonly/item_categories.csv')\n",
    "shops              = pd.read_csv('./readonly/shops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0  02.01.2013               0       59    22154      999.00           1.0\n",
       "1  03.01.2013               0       25     2552      899.00           1.0\n",
       "2  05.01.2013               0       25     2552      899.00          -1.0\n",
       "3  06.01.2013               0       25     2554     1709.05           1.0\n",
       "4  15.01.2013               0       25     2555     1099.00           1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametres\n",
    "items_sample_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include items and shops only from test\n",
    "test_shops = test['shop_id'].unique()\n",
    "test_items = test['item_id'].unique()\n",
    "\n",
    "data = sales_train[\n",
    "    sales_train['shop_id'].isin(test_shops) & \n",
    "    sales_train['item_id'].isin(test_items)].copy()\n",
    "\n",
    "# Collect item prices (taking into account that prices should not differ much from shop to shop)\n",
    "prices = sales_train.groupby(['item_id'])[['item_price']].mean()\n",
    "data.drop('item_price', axis = 1, inplace = True)\n",
    "\n",
    "# Drop column \"date\", which is not going to be used\n",
    "data.drop('date', axis = 1, inplace = True)\n",
    "\n",
    "# Get rid of mistakes in selection\n",
    "data = data[data['item_cnt_day'] >= 0]\n",
    "\n",
    "# If an item is not sold, our model should predict this fact\n",
    "sp = []\n",
    "for item in np.random.choice(test_items, items_sample_size, replace=False):\n",
    "    for date_block in range(34):\n",
    "        for shop in test_shops:\n",
    "            sp.append([date_block, shop, item, 0])\n",
    "zero_sales = pd.DataFrame(sp, columns = data.columns)\n",
    "data = pd.concat([data, zero_sales])\n",
    "\n",
    "# Making \"target\" values\n",
    "data = data.groupby([\"date_block_num\", \"shop_id\", \"item_id\"])['item_cnt_day'].sum().reset_index()\n",
    "data.rename(columns = {'item_cnt_day' : 'target'}, inplace=True)\n",
    "data.loc[:, ('target')] = data['target'].astype('int32')\n",
    "\n",
    "# Add categories' info\n",
    "data = data.join(items.set_index('item_id')['item_category_id'], on='item_id')\n",
    "data = data.join(prices, on=['item_id'])\n",
    "\n",
    "# Change test to a format of \"data\" variable\n",
    "build_test = test.join(items.set_index('item_id')['item_category_id'], on='item_id')\n",
    "build_test = build_test.join(prices, on='item_id')\n",
    "build_test.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('date_block_num', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conider the following format of data (conditions for the work of the code below): \\\n",
    "**Columns** : shop_id - item_id - item_category_id - item_price \\\n",
    "shop_id, item_id, item_category_id can't have NaNs \\\n",
    "item_price can have NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes features which depend on a part of known dataset, such as mean values\n",
    "# Also it doesn't matter if \"test_input\" has \"target\" column (for validation) or not (for the real test)\n",
    "def preparation(data_input, test_input, mean_encoding, indexes_union_for_dummies):  \n",
    "    data_train = data_input.copy()\n",
    "    data_train.loc[:, 'item_price'].fillna(data_train['item_price'].mean(), inplace=True)\n",
    "\n",
    "    data_test = test_input.copy()\n",
    "    data_test.loc[:, 'item_price'].fillna(data_train['item_price'].mean(), inplace=True)\n",
    "    \n",
    "    # Mean encoding\n",
    "    for column in mean_encoding:\n",
    "        collect_means = data_train.groupby(column)[['target']].mean()\n",
    "        collect_means.rename(columns = {'target' : 'mean_' + column}, inplace=True)\n",
    "\n",
    "        data_train = data_train.join(collect_means, on=column)\n",
    "        data_test = data_test.join(collect_means, on=column)\n",
    "        data_test = data_test.fillna(method='ffill', axis=1)\n",
    "       \n",
    "    # One Hot encoding\n",
    "    for column in list(indexes_union_for_dummies.keys()):\n",
    "        ids_union = indexes_union_for_dummies[column]\n",
    "        data_train.loc[:, column] = data_train[column].astype(pd.CategoricalDtype(categories=ids_union))\n",
    "        data_test.loc[:, column] = data_test[column].astype(pd.CategoricalDtype(categories=ids_union))\n",
    "\n",
    "        data_train = data_train.join(pd.get_dummies(data_train[column], prefix=column))\n",
    "        data_test = data_test.join(pd.get_dummies(data_test[column], prefix=column))\n",
    "\n",
    "        data_train.drop(column, axis=1, inplace=True)\n",
    "        data_test.drop(column, axis=1, inplace=True)\n",
    "        \n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 0: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.9424183467713\n",
      "109.95931521177557\n",
      "142.80673025987474\n",
      "113.93789702529644\n",
      "104.41515470788808\n"
     ]
    }
   ],
   "source": [
    "kf5 = KFold(n_splits = 5, shuffle=True)\n",
    "indexes_union_for_dummies = dict()\n",
    "mean_encoding =  []\n",
    "\n",
    "for train_index, test_index in kf5.split(data):\n",
    "    data_train, data_test = preparation(data.loc[train_index], data.loc[test_index], mean_encoding, indexes_union_for_dummies)\n",
    "    \n",
    "    X_train, X_test = data_train.drop('target', axis = 1), data_test.drop('target', axis = 1)\n",
    "    y_train, y_test = data_train['target'].astype('float32'), data_test['target'].astype('float32')\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(metrics.mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1 : Mean encoding, Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.9559944797769\n",
      "79.74611194506095\n",
      "60.093020590337574\n",
      "103.83677194208866\n",
      "59.1070037994563\n"
     ]
    }
   ],
   "source": [
    "kf5 = KFold(n_splits = 5, shuffle=True)\n",
    "indexes_union_for_dummies = dict()\n",
    "mean_encoding =  ['shop_id', 'item_id', 'item_category_id']\n",
    "\n",
    "for train_index, test_index in kf5.split(data):\n",
    "    data_train, data_test = preparation(data.loc[train_index], data.loc[test_index], mean_encoding, indexes_union_for_dummies)\n",
    "    \n",
    "    X_train, X_test = data_train.drop('target', axis = 1), data_test.drop('target', axis = 1)\n",
    "    y_train, y_test = data_train['target'].astype('float32'), data_test['target'].astype('float32')\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(metrics.mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2 : Mean encoding, One Hot encoding, Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.31937031709726\n",
      "70.72295966829721\n",
      "58.32318332747794\n",
      "98.3485151675847\n",
      "91.13921511935841\n"
     ]
    }
   ],
   "source": [
    "kf5 = KFold(n_splits = 5, shuffle=True)\n",
    "indexes_union_for_dummies = dict()\n",
    "mean_encoding =  ['shop_id', 'item_id', 'item_category_id']\n",
    "for column in ['shop_id', 'item_category_id']:\n",
    "    indexes_union_for_dummies[column] = list(set(build_test[column].unique().tolist()).union(set(data[column].unique().tolist())))\n",
    "\n",
    "for train_index, test_index in kf5.split(data):\n",
    "    data_train, data_test = preparation(data.loc[train_index], data.loc[test_index], mean_encoding, indexes_union_for_dummies)\n",
    "    \n",
    "    X_train, X_test = data_train.drop('target', axis = 1), data_test.drop('target', axis = 1)\n",
    "    y_train, y_test = data_train['target'].astype('float32'), data_test['target'].astype('float32')\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(metrics.mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have chosen approach N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = preparation(data, build_test, mean_encoding, indexes_union_for_dummies)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(data_train.drop('target', axis = 1), data_train['target'].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(lr.predict(data_test))\n",
    "\n",
    "submission.index.name = 'ID'\n",
    "submission.columns = ['item_cnt_month']\n",
    "\n",
    "submission.to_csv('./results/submbission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
