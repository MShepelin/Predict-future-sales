{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning\n",
    "- Interactive tuning\n",
    "- Parameters selection\n",
    "- Clear solution pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation = pd.read_csv('./results/dataset_for_validation.csv').drop('index', axis=1)\n",
    "data_full = pd.read_csv('./results/dataset_for_test.csv').drop('category_0', axis=1)\n",
    "val_answers = pd.read_csv('./results/validation_answers.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision_sample = pd.read_csv('./readonly/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few words should be said about unpacking our data. To separate our test and train data we use \"date_block_num\" value, but then we should make a feature out of it by making a number of month out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation, methods comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_validation[data_validation['date_block_num'] < 33].drop('target', axis=1)\n",
    "X_test = data_validation[data_validation['date_block_num'] == 33].drop('target', axis=1)\n",
    "y_train = data_validation[data_validation['date_block_num'] < 33]['target']\n",
    "y_test = val_answers[1]\n",
    "\n",
    "X_train['date_block_num'] %= 12\n",
    "X_test['date_block_num'] %= 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic lgbm**. It was vey helpful to use it to find out if dataset was built correctly without leakages and with needed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse is 1.5237335160776573\n",
      "Time spent: 0.8367640972137451\n"
     ]
    }
   ],
   "source": [
    "time_start = time()\n",
    "lgbm = LGBMRegressor(n_estimators=100, n_jobs=2)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"mse is\", mse(y_test, lgbm.predict(X_test.fillna(0))))\n",
    "print(\"Time spent:\", time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggingModel():\n",
    "    def __init__(self, arguments: list, name, verbose=False):\n",
    "        self.bag_of_models = []\n",
    "        self.name = name\n",
    "        self.verbose=verbose\n",
    "        \n",
    "        for pair in arguments:\n",
    "            if 'lgbm' == pair[0]:\n",
    "                self.bag_of_models.append(LGBMRegressor(**pair[1]))\n",
    "\n",
    "            if 'knn' == pair[0]:\n",
    "                self.bag_of_models.append(KNeighborsRegressor(**pair[1]))\n",
    "                \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        answer = np.zeros(X_test.shape[0])\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(self.name, \"is predicting...\")\n",
    "            for model in tqdm(self.bag_of_models):\n",
    "                answer +=  model.predict(X_test)\n",
    "            print(self.name, \"finished predicting\")\n",
    "            \n",
    "        else:\n",
    "            for model in self.bag_of_models:\n",
    "                answer +=  model.predict(X_test)\n",
    "            \n",
    "        answer /= len(self.bag_of_models)\n",
    "        \n",
    "        return answer\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, y_train):    \n",
    "        if self.verbose:\n",
    "            print(self.name, \"is fitting...\")\n",
    "            for model in tqdm(self.bag_of_models):\n",
    "                model.fit(X_train, y_train)\n",
    "            print(self.name, \"finished fitting\")\n",
    "                \n",
    "        else:\n",
    "            for model in self.bag_of_models:\n",
    "                model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM_Bagging is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM_Bagging finished fitting\n",
      "LGBM_Bagging is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM_Bagging finished predicting\n",
      "mse is 1.5130420752105236\n",
      "Time spent: 1.9966630935668945\n"
     ]
    }
   ],
   "source": [
    "time_start = time()\n",
    "model = BaggingModel([('lgbm', {'n_estimators': 64, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 64}), \n",
    "                       ('lgbm', {'n_estimators': 128, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 32}),\n",
    "                       ('lgbm', {'n_estimators': 128, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 16})\n",
    "                     ], 'LGBM_Bagging', True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"mse is\", mse(y_test, model.predict(X_test.fillna(0))))\n",
    "print(\"Time spent:\", time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingModel():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.levels = []\n",
    "        \n",
    "    def append(self, models: list):\n",
    "        assert models != [], \"Input is empty\"\n",
    "        self.levels.append(models)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        assert self.levels != [], \"Model is empty\"\n",
    "        assert self.levels[-1], \"Model has wrong output\"\n",
    "        \n",
    "        print(self.name, \"is predicting...\")\n",
    "        \n",
    "        level_output = X_test\n",
    "        for level in tqdm(self.levels):\n",
    "            level_output = np.concatenate([\n",
    "                model.predict(level_output).reshape(-1, 1) for model in level\n",
    "            ], axis=1)\n",
    "        \n",
    "        print(self.name, \"finished predicting\")\n",
    "        \n",
    "        return level_output.reshape(-1, 1)\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "       \n",
    "        assert self.levels != [], \"Model is empty\"\n",
    "        assert self.levels[-1], \"Model has wrong output\"\n",
    "        \n",
    "        print(self.name, \"is fitting...\")\n",
    "        \n",
    "        level_output = X_train\n",
    "        for level in tqdm(self.levels):\n",
    "            for model in level:\n",
    "                model.fit(level_output, y_train)\n",
    "            \n",
    "            level_output = np.concatenate([\n",
    "                model.predict(level_output).reshape(-1, 1) for model in level\n",
    "            ], axis=1)\n",
    "\n",
    "        print(self.name, \"finished fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Machine is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Machine finished fitting\n",
      "Stacking Machine is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Machine finished predicting\n",
      "mse is 1.5313531353135315\n",
      "Time spent: 3.684155225753784\n"
     ]
    }
   ],
   "source": [
    "time_start = time()\n",
    "model = StackingModel(\"Stacking Machine\")\n",
    "model.append([LGBMRegressor(n_jobs=8), LGBMRegressor(n_jobs=8), LGBMRegressor(n_jobs=8)])\n",
    "model.append([LGBMRegressor(n_jobs=8), LGBMRegressor(n_jobs=8)])\n",
    "model.append([KNeighborsRegressor()])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"mse is\", mse(y_test, model.predict(X_test.fillna(0))))\n",
    "print(\"Time spent:\", time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solvator-2000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:17<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 finished fitting\n",
      "Solvator-2000 is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:01<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 finished predicting\n",
      "mse is 0.692785511745209\n",
      "Time spent: 18.311983108520508\n"
     ]
    }
   ],
   "source": [
    "time_start = time()\n",
    "\n",
    "# Model building\n",
    "bag1 = BaggingModel([('lgbm', {'n_estimators': 64, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 64}), \n",
    "                       ('lgbm', {'n_estimators': 128, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 32}),\n",
    "                       ('lgbm', {'n_estimators': 128, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 16})\n",
    "                     ], 'LGBM_Bagging', False)\n",
    "bag2 = BaggingModel([('knn', {'leaf_size': 64, 'n_neighbors': 50, 'n_jobs': 8}), \n",
    "                       ('knn', {'leaf_size': 32, 'n_neighbors': 100, 'n_jobs': 8}), \n",
    "                       ('knn', {'leaf_size': 64, 'n_neighbors': 10, 'n_jobs': 8})\n",
    "                     ], 'kNN_Bagging', False)\n",
    "model = StackingModel(\"Solvator-2000\")\n",
    "model.append([bag1, bag2])\n",
    "model.append([SGDRegressor(), RandomForestRegressor(n_estimators=128, n_jobs= 8, random_state=42)])\n",
    "model.append([LinearRegression()])\n",
    "\n",
    "# Model fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"mse is\", mse(y_test, model.predict(X_test.fillna(0)).clip(0, 20)))\n",
    "print(\"Time spent:\", time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For submission we chose Solvator-2000 because of the cool name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subm = data_full[data_full['date_block_num'] < 34].drop('target', axis=1)\n",
    "X_test_subm = data_full[data_full['date_block_num'] == 34].drop('target', axis=1)\n",
    "y_train_subm = data_full[data_full['date_block_num'] < 34]['target']\n",
    "\n",
    "X_train_subm['date_block_num'] %= 12\n",
    "X_test_subm['date_block_num'] %= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 is fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:25<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 finished fitting\n",
      "Time spent: 25.68553352355957\n"
     ]
    }
   ],
   "source": [
    "time_start = time()\n",
    "\n",
    "# Model building\n",
    "bag1 = BaggingModel([('lgbm', {'n_estimators': 64, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 64}), \n",
    "                       ('lgbm', {'n_estimators': 128, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 32}),\n",
    "                       ('lgbm', {'n_estimators': 128, 'n_jobs': 8, 'random_state': 42, 'num_leaves': 16})\n",
    "                     ], 'LGBM_Bagging', False)\n",
    "bag2 = BaggingModel([('knn', {'leaf_size': 64, 'n_neighbors': 50, 'n_jobs': 8}), \n",
    "                       ('knn', {'leaf_size': 32, 'n_neighbors': 100, 'n_jobs': 8}), \n",
    "                       ('knn', {'leaf_size': 64, 'n_neighbors': 10, 'n_jobs': 8})\n",
    "                     ], 'kNN_Bagging', False)\n",
    "model = StackingModel(\"Solvator-2000\")\n",
    "model.append([bag1, bag2])\n",
    "model.append([SGDRegressor(), RandomForestRegressor(n_estimators=128, n_jobs= 8, random_state=42)])\n",
    "model.append([LinearRegression()])\n",
    "\n",
    "# Model fit\n",
    "model.fit(X_train_subm, y_train_subm)\n",
    "\n",
    "print(\"Time spent:\", time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227674, 189)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full[data_full['target'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1130, 189)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full[data_full['target'] != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [02:08<00:00, 42.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 finished predicting\n"
     ]
    }
   ],
   "source": [
    "submision_sample['item_cnt_month'] = model.predict(X_test_subm).clip(0, 20)\n",
    "submision_sample.to_csv('./results/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvator-2000 is predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 188 and input n_features is 155 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-f8567707d612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mse is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-dd8d866be9fc>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             level_output = np.concatenate([\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             ], axis=1)\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-dd8d866be9fc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             level_output = np.concatenate([\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             ], axis=1)\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-91d116b9b23a>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbag_of_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0manswer\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbag_of_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shepe\\python\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m                              \u001b[1;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                              % (self._n_features, n_features))\n\u001b[0m\u001b[0;32m    664\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m    665\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 188 and input n_features is 155 "
     ]
    }
   ],
   "source": [
    "print(\"mse is\", mse(y_test, model.predict(X_test.fillna(0))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
